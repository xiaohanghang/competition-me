{"cells":[
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Psychology of a Professional Athlete"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom matplotlib.patches import Circle, Rectangle, Arc\nfrom sklearn import mixture\nfrom sklearn import ensemble\nfrom sklearn import cross_validation\nfrom sklearn.metrics import accuracy_score as accuracy\nfrom sklearn.metrics import log_loss\nimport time\nimport itertools\nimport operator\n\n#%% load training data\n\nallData = pd.read_csv('../input/data.csv')\ndata = allData[allData['shot_made_flag'].notnull()].reset_index()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% add some temporal columns to the data\n\ndata['game_date_DT'] = pd.to_datetime(data['game_date'])\ndata['dayOfWeek'] = data['game_date_DT'].dt.dayofweek\ndata['dayOfYear'] = data['game_date_DT'].dt.dayofyear\n\ndata['secondsFromPeriodEnd'] = 60*data['minutes_remaining']+data['seconds_remaining']\ndata['secondsFromPeriodStart'] = 60*(11-data['minutes_remaining'])+(60-data['seconds_remaining'])\ndata['secondsFromGameStart'] = (data['period'] <= 4).astype(int)*(data['period']-1)*12*60 + (data['period'] > 4).astype(int)*((data['period']-4)*5*60 + 3*12*60) + data['secondsFromPeriodStart']\n\n# look at first couple of rows and verify that everything is good\ndata.ix[:20,['period','minutes_remaining','seconds_remaining','secondsFromGameStart']]"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## First, as initial exploration let's examine the temporal aspect of Kobe's shots\nhere we apply 3 different binnings of time and show the attempts as function from game start"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% plot the shot attempts as a function of time (from start of game) with several different binnings\nplt.rcParams['figure.figsize'] = (16, 10)\n\nbinsSizes = [24,12,6]\n\nplt.figure();\nfor k, binSizeInSeconds in enumerate(binsSizes):\n    timeBins = np.arange(0,60*(4*12+3*5),binSizeInSeconds)+0.01\n    attemptsAsFunctionOfTime, b = np.histogram(data['secondsFromGameStart'], bins=timeBins)     \n    \n    maxHeight = max(attemptsAsFunctionOfTime) + 30\n    barWidth = 0.999*(timeBins[1]-timeBins[0])\n    plt.subplot(len(binsSizes),1,k+1); \n    plt.bar(timeBins[:-1],attemptsAsFunctionOfTime, align='edge', width=barWidth); plt.title(str(binSizeInSeconds) + ' second time bins')\n    plt.vlines(x=[0,12*60,2*12*60,3*12*60,4*12*60,4*12*60+5*60,4*12*60+2*5*60,4*12*60+3*5*60], ymin=0,ymax=maxHeight, colors='r')\n    plt.xlim((-20,3200)); plt.ylim((0,maxHeight)); plt.ylabel('attempts')\nplt.xlabel('time [seconds from start of game]')\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### It looks like Kobe is entrusted to take the last shot of every period\nit also looks like he's usually on the bench at the start of 2nd and 4th periods"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Now let's plot the accuracy as function of time since game start as well"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% plot the accuracy as a function of time\nplt.rcParams['figure.figsize'] = (15, 10)\n\nbinSizeInSeconds = 20\ntimeBins = np.arange(0,60*(4*12+3*5),binSizeInSeconds)+0.01\nattemptsAsFunctionOfTime, b = np.histogram(data['secondsFromGameStart'], bins=timeBins)     \nmadeAttemptsAsFunctionOfTime, b = np.histogram(data.ix[data['shot_made_flag']==1,'secondsFromGameStart'], bins=timeBins)     \naccuracyAsFunctionOfTime = madeAttemptsAsFunctionOfTime.astype(float)/attemptsAsFunctionOfTime\naccuracyAsFunctionOfTime[attemptsAsFunctionOfTime <= 50] = 0 # zero accuracy in bins that don't have enough samples\n\nmaxHeight = max(attemptsAsFunctionOfTime) + 30\nbarWidth = 0.999*(timeBins[1]-timeBins[0])\n \nplt.figure();\nplt.subplot(2,1,1); plt.bar(timeBins[:-1],attemptsAsFunctionOfTime, align='edge', width=barWidth); \nplt.xlim((-20,3200)); plt.ylim((0,maxHeight)); plt.ylabel('attempts'); plt.title(str(binSizeInSeconds) + ' second time bins')\nplt.vlines(x=[0,12*60,2*12*60,3*12*60,4*12*60,4*12*60+5*60,4*12*60+2*5*60,4*12*60+3*5*60], ymin=0,ymax=maxHeight, colors='r')\nplt.subplot(2,1,2); plt.bar(timeBins[:-1],accuracyAsFunctionOfTime, align='edge', width=barWidth); \nplt.xlim((-20,3200)); plt.ylabel('accuracy'); plt.xlabel('time [seconds from start of game]')\nplt.vlines(x=[0,12*60,2*12*60,3*12*60,4*12*60,4*12*60+5*60,4*12*60+2*5*60,4*12*60+3*5*60], ymin=0.0,ymax=0.7, colors='r')\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Note that the accuracy of these \"last second shots\" is consisently lower than usuall\nthis is probably due to the fact that a large amonut of these shots are from very far away"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## Now let's continue our initial exploration and examine the spatial location aspect of kobe's shots\nwe'll do this by building a gaussian mixture model that tries to explain Kobe's shot locations"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% cluster the shot attempts of kobe using GMM on their location\n\nnumGaussians = 13\ngaussianMixtureModel = mixture.GMM(n_components=numGaussians, covariance_type='full', \n                                   params='wmc', init_params='wmc',\n                                   random_state=1, n_init=3,  verbose=0)\ngaussianMixtureModel.fit(data.ix[:,['loc_x','loc_y']])\n\ndata['shotLocationCluster'] = gaussianMixtureModel.predict(data.ix[:,['loc_x','loc_y']])"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "let's define some helper functions\n### (draw_court() is shamelessly stolen from **MichaelKrueger**'s excelent script)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% define draw functions (stealing shamelessly the draw_court() function from MichaelKrueger's excelent script)\n\ndef draw_court(ax=None, color='black', lw=2, outer_lines=False):\n    # If an axes object isn't provided to plot onto, just get current one\n    if ax is None:\n        ax = plt.gca()\n\n    # Create the various parts of an NBA basketball court\n\n    # Create the basketball hoop\n    # Diameter of a hoop is 18\" so it has a radius of 9\", which is a value\n    # 7.5 in our coordinate system\n    hoop = Circle((0, 0), radius=7.5, linewidth=lw, color=color, fill=False)\n\n    # Create backboard\n    backboard = Rectangle((-30, -7.5), 60, -1, linewidth=lw, color=color)\n\n    # The paint\n    # Create the outer box 0f the paint, width=16ft, height=19ft\n    outer_box = Rectangle((-80, -47.5), 160, 190, linewidth=lw, color=color,\n                          fill=False)\n    # Create the inner box of the paint, widt=12ft, height=19ft\n    inner_box = Rectangle((-60, -47.5), 120, 190, linewidth=lw, color=color,\n                          fill=False)\n\n    # Create free throw top arc\n    top_free_throw = Arc((0, 142.5), 120, 120, theta1=0, theta2=180,\n                         linewidth=lw, color=color, fill=False)\n    # Create free throw bottom arc\n    bottom_free_throw = Arc((0, 142.5), 120, 120, theta1=180, theta2=0,\n                            linewidth=lw, color=color, linestyle='dashed')\n    # Restricted Zone, it is an arc with 4ft radius from center of the hoop\n    restricted = Arc((0, 0), 80, 80, theta1=0, theta2=180, linewidth=lw,\n                     color=color)\n\n    # Three point line\n    # Create the side 3pt lines, they are 14ft long before they begin to arc\n    corner_three_a = Rectangle((-220, -47.5), 0, 140, linewidth=lw,\n                               color=color)\n    corner_three_b = Rectangle((220, -47.5), 0, 140, linewidth=lw, color=color)\n    # 3pt arc - center of arc will be the hoop, arc is 23'9\" away from hoop\n    # I just played around with the theta values until they lined up with the \n    # threes\n    three_arc = Arc((0, 0), 475, 475, theta1=22, theta2=158, linewidth=lw,\n                    color=color)\n\n    # Center Court\n    center_outer_arc = Arc((0, 422.5), 120, 120, theta1=180, theta2=0,\n                           linewidth=lw, color=color)\n    center_inner_arc = Arc((0, 422.5), 40, 40, theta1=180, theta2=0,\n                           linewidth=lw, color=color)\n\n    # List of the court elements to be plotted onto the axes\n    court_elements = [hoop, backboard, outer_box, inner_box, top_free_throw,\n                      bottom_free_throw, restricted, corner_three_a,\n                      corner_three_b, three_arc, center_outer_arc,\n                      center_inner_arc]\n\n    if outer_lines:\n        # Draw the half court line, baseline and side out bound lines\n        outer_lines = Rectangle((-250, -47.5), 500, 470, linewidth=lw,\n                                color=color, fill=False)\n        court_elements.append(outer_lines)\n\n    # Add the court elements onto the axes\n    for element in court_elements:\n        ax.add_patch(element)\n\n    return ax\n\ndef Draw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages):\n    \n    fig, h = plt.subplots();\n    for i, (mean, covarianceMatrix) in enumerate(zip(gaussianMixtureModel.means_, gaussianMixtureModel._get_covars())):\n        # get the eigen vectors and eigen values of the covariance matrix\n        v, w = np.linalg.eigh(covarianceMatrix)\n        v = 2.5*np.sqrt(v) # go to units of standard deviation instead of variance\n        \n        # calculate the ellipse angle and two axis length and draw it\n        u = w[0] / np.linalg.norm(w[0])    \n        angle = np.arctan(u[1] / u[0])\n        angle = 180 * angle / np.pi  # convert to degrees\n        currEllipse = mpl.patches.Ellipse(mean, v[0], v[1], 180 + angle, color=ellipseColors[i])\n        currEllipse.set_alpha(0.5)\n        h.add_artist(currEllipse)\n        h.text(mean[0]+7, mean[1]-1, ellipseTextMessages[i], fontsize=12)\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% show gaussian mixture elipses of shot attempts\nplt.rcParams['figure.figsize'] = (11, 8)\n\nellipseTextMessages = [str(100*gaussianMixtureModel.weights_[x])[:4]+'%' for x in range(numGaussians)]\nellipseColors = ['red','green','purple','cyan','magenta','yellow','blue','orange','silver','maroon','lime','olive','brown','darkblue']\nDraw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages)\ndraw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270); plt.title('shot attempts')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### We can see that Kobe is making more attempts from the left side of the court (or right side from his point of view)\nthis is probably because he's right handed\n### Also, we can see that a huge number of attempts (16.8%) is from directly under the basket \nand 5.4% additinal attemps are from very close to the basket\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Just to make sure the gaussian model actually captures something, show the scatter plot of all Kobe's shot attempts colored by the cluster assignment according to the GMM"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% just to make sure the gaussian model actually captures something, show the scatter and cluster assignment\n\nplt.rcParams['figure.figsize'] = (11, 9)\n\nplt.figure(); draw_court(outer_lines=True); plt.ylim(-60,500); plt.xlim(270,-270); plt.title('cluser assignment')\nplt.scatter(x=data['loc_x'],y=data['loc_y'],c=data['shotLocationCluster'],s=40,cmap='hsv',alpha=0.1)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### It doesn't seem perfect, but definatly captures some interesting things about the data\nfor example, we can see that the large and very far away cluster is capturing all of the very distant shots"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Now let's plot the accuracy of each cluster to get a feel what are easy and what are difficult shots"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% for each cluster, calculate it's individual accuracy and plot it\n\nplt.rcParams['figure.figsize'] = (11, 8)\n\nvariableCategories = data['shotLocationCluster'].value_counts().index.tolist()\n\nclusterAccuracy = {}\nfor category in variableCategories:\n    shotsAttempted = np.array(data['shotLocationCluster'] == category).sum()\n    shotsMade = np.array(data.ix[data['shotLocationCluster'] == category,'shot_made_flag'] == 1).sum()\n    clusterAccuracy[category] = float(shotsMade)/shotsAttempted\n\nellipseTextMessages = [str(100*clusterAccuracy[x])[:4]+'%' for x in range(numGaussians)]\nDraw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages)\ndraw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270); plt.title('shot accuracy')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### We can clearly see the dependence between distance and accuracy\nAnother interesting fact is that Kobe not only makes more attempts from the right side (from his point of view), but also he's better at making those attempts"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Now let's try and plot a 2D spatio-temporal plot of Kobe's career\non x-axis there will be time since start of game\n\non y-axis there will be from which cluster Kobe made the shot (sorted by the cluster accuracy)\n\nthe intensity will be the number of attempts by Kobe from that particular cluster at that particular time"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% plot a 2-d spatio-temporal histogram of kobe's games during his entire carrer\n\nplt.rcParams['figure.figsize'] = (17, 9)\n\n# sort the clusters according to their accuracy\nsortedClustersByAccuracyTuple = sorted(clusterAccuracy.items(), key=operator.itemgetter(1),reverse=True)\nsortedClustersByAccuracy = [x[0] for x in sortedClustersByAccuracyTuple]\n\nbinSizeInSeconds = 12\ntimeInUnitsOfBins = ((data['secondsFromGameStart']+0.0001)/binSizeInSeconds).astype(int)\nlocationInUintsOfClusters = np.array([sortedClustersByAccuracy.index(data.ix[x,'shotLocationCluster']) for x in range(data.shape[0])])\n\n# build a spatio-temporal histogram of Kobe's games\nshotAttempts = np.zeros((gaussianMixtureModel.n_components,1+max(timeInUnitsOfBins)))\nfor shot in range(data.shape[0]):\n    shotAttempts[locationInUintsOfClusters[shot],timeInUnitsOfBins[shot]] += 1\n\nshotAttempts = np.kron(shotAttempts,np.ones((2,1)))\n\nplt.figure(); \nplt.imshow(shotAttempts, cmap='copper',interpolation=\"nearest\"); plt.xlim(0,float(4*12*60+6*60)/binSizeInSeconds);\nplt.vlines(x=0.5001+np.array([0,12*60,2*12*60,3*12*60,4*12*60,4*12*60+5*60]).astype(int)/binSizeInSeconds, ymin=-0.5,ymax=25.5, colors='r')\nplt.xlabel('time from start of game [sec]'); plt.ylabel('cluster (sorted by accuracy)')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### We can now see that the \"last second shots\" in the 1st, 2nd and 3rd periods were indeed \"hopeless shots\" from very far away\nIt's interesting to note, however, that in the 4th period, the last second shot don't belong to the \"hopeless\" cluster, but rather to the regular 3-pointer clusters (which are still much more difficult, but not hopeless)\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### For later analysis, we'll want to assess shot difficulty based on shot properties\n(such as shot type and shot distance)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% create a new table for shot difficulty model\n\ndef FactorizeCategoricalVariable(inputDB,categoricalVarName):\n    opponentCategories = inputDB[categoricalVarName].value_counts().index.tolist()\n    \n    outputDB = pd.DataFrame()\n    for category in opponentCategories:\n        featureName = categoricalVarName + ': ' + str(category)\n        outputDB[featureName] = (inputDB[categoricalVarName] == category).astype(int)\n\n    return outputDB\n\nfeaturesDB = pd.DataFrame()\nfeaturesDB['homeGame'] = data['matchup'].apply(lambda x: 1 if (x.find('@') < 0) else 0)\nfeaturesDB = pd.concat([featuresDB,FactorizeCategoricalVariable(data,'opponent')],axis=1)\nfeaturesDB = pd.concat([featuresDB,FactorizeCategoricalVariable(data,'action_type')],axis=1)\nfeaturesDB = pd.concat([featuresDB,FactorizeCategoricalVariable(data,'shot_type')],axis=1)\nfeaturesDB = pd.concat([featuresDB,FactorizeCategoricalVariable(data,'combined_shot_type')],axis=1)\nfeaturesDB = pd.concat([featuresDB,FactorizeCategoricalVariable(data,'shot_zone_basic')],axis=1)\nfeaturesDB = pd.concat([featuresDB,FactorizeCategoricalVariable(data,'shot_zone_area')],axis=1)\nfeaturesDB = pd.concat([featuresDB,FactorizeCategoricalVariable(data,'shot_zone_range')],axis=1)\nfeaturesDB = pd.concat([featuresDB,FactorizeCategoricalVariable(data,'shotLocationCluster')],axis=1)\n\nfeaturesDB['playoffGame'] = data['playoffs']\nfeaturesDB['locX'] = data['loc_x']\nfeaturesDB['locY'] = data['loc_y']\nfeaturesDB['distanceFromBasket'] = data['shot_distance']\nfeaturesDB['secondsFromPeriodEnd'] = data['secondsFromPeriodEnd']\n\nfeaturesDB['dayOfWeek_cycX'] = np.sin(2*np.pi*(data['dayOfWeek']/7))\nfeaturesDB['dayOfWeek_cycY'] = np.cos(2*np.pi*(data['dayOfWeek']/7))\nfeaturesDB['timeOfYear_cycX'] = np.sin(2*np.pi*(data['dayOfYear']/365))\nfeaturesDB['timeOfYear_cycY'] = np.cos(2*np.pi*(data['dayOfYear']/365))\n\nlabelsDB = data['shot_made_flag']"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## Build a model based on featuresDB table, and make sure it doesn't overfit \n(i.e. the training error and the test error are the same)\n#### Use an ExtraTreesClassifier for that"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% build a simple model and make sure it doesnt overfit\n\nrandomSeed = 1\nnumFolds = 4\n\nmainLearner = ensemble.ExtraTreesClassifier(n_estimators=500, max_depth=5, \n                                            min_samples_leaf=120, max_features=120, \n                                            criterion='entropy', bootstrap=False, \n                                            n_jobs=-1, random_state=randomSeed)\n                        \ncrossValidationIterator = cross_validation.StratifiedKFold(labelsDB, n_folds=numFolds, \n                                                           shuffle=True, random_state=randomSeed)\n\nstartTime = time.time()\ntrainAccuracy = []; validAccuracy = [];\ntrainLogLosses = []; validLogLosses = []\nfor trainInds, validInds in crossValidationIterator:\n    # split to train and valid sets\n    X_train_CV = featuresDB.ix[trainInds,:]\n    y_train_CV = labelsDB.iloc[trainInds]\n    X_valid_CV = featuresDB.ix[validInds,:]\n    y_valid_CV = labelsDB.iloc[validInds]\n    \n    # train learner\n    mainLearner.fit(X_train_CV, y_train_CV)\n    \n    # make predictions\n    y_train_hat_mainLearner = mainLearner.predict_proba(X_train_CV)[:,1]\n    y_valid_hat_mainLearner = mainLearner.predict_proba(X_valid_CV)[:,1]\n\n    # store results\n    trainAccuracy.append(accuracy(y_train_CV, y_train_hat_mainLearner > 0.5))\n    validAccuracy.append(accuracy(y_valid_CV, y_valid_hat_mainLearner > 0.5))\n    trainLogLosses.append(log_loss(y_train_CV, y_train_hat_mainLearner))\n    validLogLosses.append(log_loss(y_valid_CV, y_valid_hat_mainLearner))\n\nprint(\"-----------------------------------------------------\")\nprint(\"total (train,valid) Accuracy = (%.5f,%.5f). took %.2f minutes\" % (np.mean(trainAccuracy),np.mean(validAccuracy), (time.time()-startTime)/60))\nprint(\"total (train,valid) Log Loss = (%.5f,%.5f). took %.2f minutes\" % (np.mean(trainLogLosses),np.mean(validLogLosses), (time.time()-startTime)/60))\nprint(\"-----------------------------------------------------\")\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Use the model to add a \"shotDifficulty\" field to every original shot entry\n(which is actually the predicted probability of making the shot. meaning, the name is a bit confusing right now)\n### Also, to get a feel for the important features, let's look at the feature importances according to ET Classifier"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "mainLearner.fit(featuresDB, labelsDB)\ndata['shotDifficulty'] = mainLearner.predict_proba(featuresDB)[:,1]\n\n# just to get a feel for what determins shot difficulty, look at feature importances\nfeatureInds = mainLearner.feature_importances_.argsort()[::-1]\nfeatureImportance = pd.DataFrame(np.concatenate((featuresDB.columns[featureInds,None], mainLearner.feature_importances_[featureInds,None]), axis=1),\n                                  columns=['featureName', 'importanceET'])\n\nfeatureImportance.ix[:40,:]"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## We would like to asses some aspects of the decision making process of Kobe Bryant\n### For that we will collect two distinct groups of shots and analyse the differences between them:\n\n(1) the shots that came right after a sucessful shot attempt\n\n(2) the shots that came right after a missed shot attempt"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% collect data given that kobe made or missed last shot\n\ntimeBetweenShotsDict = {}\ntimeBetweenShotsDict['madeLast'] = []\ntimeBetweenShotsDict['missedLast'] = []\n\nchangeInDistFromBasketDict = {}\nchangeInDistFromBasketDict['madeLast'] = []\nchangeInDistFromBasketDict['missedLast'] = []\n\nchangeInShotDifficultyDict = {}\nchangeInShotDifficultyDict['madeLast'] = []\nchangeInShotDifficultyDict['missedLast'] = []\n\nafterMadeShotsList = []\nafterMissedShotsList = []\n\nfor shot in range(1,data.shape[0]):\n\n    # make sure the current shot and last shot were all in the same period of the same game\n    sameGame   = data.ix[shot,'game_date'] == data.ix[shot-1,'game_date']\n    samePeriod = data.ix[shot,'period']    == data.ix[shot-1,'period']\n\n    if samePeriod and sameGame:\n        madeLastShot       = data.ix[shot-1,'shot_made_flag'] == 1\n        missedLastShot     = data.ix[shot-1,'shot_made_flag'] == 0\n        \n        timeDifferenceFromLastShot = data.ix[shot,'secondsFromGameStart']     - data.ix[shot-1,'secondsFromGameStart']\n        distDifferenceFromLastShot = data.ix[shot,'shot_distance']            - data.ix[shot-1,'shot_distance']\n        shotDifficultyDifferenceFromLastShot = data.ix[shot,'shotDifficulty'] - data.ix[shot-1,'shotDifficulty']\n\n        # check for currupt data points (assuming all samples should have been chronologically ordered)\n        if timeDifferenceFromLastShot < 0:\n            continue\n        \n        if madeLastShot:\n            timeBetweenShotsDict['madeLast'].append(timeDifferenceFromLastShot)\n            changeInDistFromBasketDict['madeLast'].append(distDifferenceFromLastShot)\n            changeInShotDifficultyDict['madeLast'].append(shotDifficultyDifferenceFromLastShot)\n            afterMadeShotsList.append(shot)\n            \n        if missedLastShot:\n            timeBetweenShotsDict['missedLast'].append(timeDifferenceFromLastShot)\n            changeInDistFromBasketDict['missedLast'].append(distDifferenceFromLastShot)\n            changeInShotDifficultyDict['missedLast'].append(shotDifficultyDifferenceFromLastShot)\n            afterMissedShotsList.append(shot)\n\nafterMissedData = data.ix[afterMissedShotsList,:]\nafterMadeData = data.ix[afterMadeShotsList,:]\n\nshotChancesListAfterMade = afterMadeData['shotDifficulty'].tolist()\ntotalAttemptsAfterMade   = afterMadeData.shape[0]\ntotalMadeAfterMade       = np.array(afterMadeData['shot_made_flag'] == 1).sum()\n\nshotChancesListAfterMissed = afterMissedData['shotDifficulty'].tolist()\ntotalAttemptsAfterMissed   = afterMissedData.shape[0]\ntotalMadeAfterMissed = np.array(afterMissedData['shot_made_flag'] == 1).sum()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Plot histogram of \"Time Since Last Shot Attempt\" for the two groups\nIt looks like after making a shot, kobe is a little bit more eager to throw the next shot"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% after making a shot, kobe wants more\nplt.rcParams['figure.figsize'] = (10, 7)\n\njointHist, timeBins = np.histogram(timeBetweenShotsDict['madeLast']+timeBetweenShotsDict['missedLast'],bins=200)\nbarWidth = 0.999*(timeBins[1]-timeBins[0])\n\ntimeDiffHist_GivenMadeLastShot, b = np.histogram(timeBetweenShotsDict['madeLast'],bins=timeBins)\ntimeDiffHist_GivenMissedLastShot, b = np.histogram(timeBetweenShotsDict['missedLast'],bins=timeBins)\nmaxHeight = max(max(timeDiffHist_GivenMadeLastShot),max(timeDiffHist_GivenMissedLastShot)) + 30\n\nplt.figure();\nplt.subplot(2,1,1); plt.bar(timeBins[:-1], timeDiffHist_GivenMadeLastShot, width=barWidth); plt.xlim((0,500)); plt.ylim((0,maxHeight))\nplt.title('made last shot'); plt.ylabel('counts')\nplt.subplot(2,1,2); plt.bar(timeBins[:-1], timeDiffHist_GivenMissedLastShot, width=barWidth); plt.xlim((0,500)); plt.ylim((0,maxHeight))\nplt.title('missed last shot'); plt.xlabel('time since last shot'); plt.ylabel('counts')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### To everyone who is wondering about why is there a \"silent period\" after a made shot, it's most likely because the ball is transfered to the other team after a sucesfull shot and it takes some time to get the ball back\nTo better visualize this difference between the histograms, let's look at cumulative histograms"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% to make the difference clearer, show the cumulative histogram\nplt.rcParams['figure.figsize'] = (10, 7)\n\ntimeDiffCumHist_GivenMadeLastShot = np.cumsum(timeDiffHist_GivenMadeLastShot).astype(float)\ntimeDiffCumHist_GivenMadeLastShot = timeDiffCumHist_GivenMadeLastShot/max(timeDiffCumHist_GivenMadeLastShot)\ntimeDiffCumHist_GivenMissedLastShot = np.cumsum(timeDiffHist_GivenMissedLastShot).astype(float)\ntimeDiffCumHist_GivenMissedLastShot = timeDiffCumHist_GivenMissedLastShot/max(timeDiffCumHist_GivenMissedLastShot)\n\nmaxHeight = max(timeDiffCumHist_GivenMadeLastShot[-1],timeDiffCumHist_GivenMissedLastShot[-1])\n\nplt.figure();\nmadePrev = plt.plot(timeBins[:-1], timeDiffCumHist_GivenMadeLastShot, label='made Prev'); plt.xlim((0,500))\nmissedPrev = plt.plot(timeBins[:-1], timeDiffCumHist_GivenMissedLastShot, label='missed Prev'); plt.xlim((0,500)); plt.ylim((0,1))\nplt.title('cumulative density function - CDF'); plt.xlabel('time since last shot'); plt.legend(loc='lower right')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Plot histogram of \"Current Shot Distance - Previous Shot Distance\" for the two groups\nNote that if Kobe throws from close by, and then from far away, this will result in positive values of \"curr shot distance - prev shot distance\"\nand vise versa. If Kobe throws from far away and then from close by, this will result in negative values."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% after making a shot, kobe is a more confident and throws from further away\nplt.rcParams['figure.figsize'] = (10, 7)\n\njointHist, distDiffBins = np.histogram(changeInDistFromBasketDict['madeLast']+changeInDistFromBasketDict['missedLast'],bins=100,density=False)\nbarWidth = 0.999*(distDiffBins[1]-distDiffBins[0])\n\ndistDiffHist_GivenMadeLastShot, b = np.histogram(changeInDistFromBasketDict['madeLast'],bins=distDiffBins)\ndistDiffHist_GivenMissedLastShot, b = np.histogram(changeInDistFromBasketDict['missedLast'],bins=distDiffBins)\nmaxHeight = max(max(distDiffHist_GivenMadeLastShot),max(distDiffHist_GivenMissedLastShot)) + 30\n\nplt.figure();\nplt.subplot(2,1,1); plt.bar(distDiffBins[:-1], distDiffHist_GivenMadeLastShot, width=barWidth); plt.xlim((-40,40)); plt.ylim((0,maxHeight))\nplt.title('made last shot'); plt.ylabel('counts')\nplt.subplot(2,1,2); plt.bar(distDiffBins[:-1], distDiffHist_GivenMissedLastShot, width=barWidth); plt.xlim((-40,40)); plt.ylim((0,maxHeight))\nplt.title('missed last shot'); plt.xlabel('curr shot distance - prev shot distance'); plt.ylabel('counts')\n\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "We can clearly see that the made group of shots is more leaning to the right\n### It therefore looks like Kobe is more confident after making a shot, and because of it, he takes a larger risk and throws from further away\nThis is even more evident than the previous plot, but let's plot the cumulative histograms again to make it clearer"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% to make the difference clearer, show the cumulative histogram\nplt.rcParams['figure.figsize'] = (10, 7)\n\ndistDiffCumHist_GivenMadeLastShot = np.cumsum(distDiffHist_GivenMadeLastShot).astype(float)\ndistDiffCumHist_GivenMadeLastShot = distDiffCumHist_GivenMadeLastShot/max(distDiffCumHist_GivenMadeLastShot)\ndistDiffCumHist_GivenMissedLastShot = np.cumsum(distDiffHist_GivenMissedLastShot).astype(float)\ndistDiffCumHist_GivenMissedLastShot = distDiffCumHist_GivenMissedLastShot/max(distDiffCumHist_GivenMissedLastShot)\n\nmaxHeight = max(distDiffCumHist_GivenMadeLastShot[-1],distDiffCumHist_GivenMissedLastShot[-1])\n\nplt.figure();\nmadePrev = plt.plot(distDiffBins[:-1], distDiffCumHist_GivenMadeLastShot, label='made Prev'); plt.xlim((-40,40))\nmissedPrev = plt.plot(distDiffBins[:-1], distDiffCumHist_GivenMissedLastShot, label='missed Prev'); plt.xlim((-40,40)); plt.ylim((0,1))\nplt.title('cumulative density function - CDF'); plt.xlabel('curr shot distance - prev shot distance'); plt.legend(loc='lower right')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## Lastly, Let's plot the \"Shot Difficulty\" change for the two groups\nhere negative values indicate that kobe took a larger risk, and positive values indicate that kobe made a safer subsequent shot"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% after making a shot, kobe is a more confident and makes much more difficult shots generally\nplt.rcParams['figure.figsize'] = (10, 7)\n\njointHist, difficultyDiffBins = np.histogram(changeInShotDifficultyDict['madeLast']+changeInShotDifficultyDict['missedLast'],bins=100)\nbarWidth = 0.999*(difficultyDiffBins[1]-difficultyDiffBins[0])\n\nshotDifficultyDiffHist_GivenMadeLastShot, b = np.histogram(changeInShotDifficultyDict['madeLast'],bins=difficultyDiffBins)\nshotDifficultyDiffHist_GivenMissedLastShot, b = np.histogram(changeInShotDifficultyDict['missedLast'],bins=difficultyDiffBins)\nmaxHeight = max(max(shotDifficultyDiffHist_GivenMadeLastShot),max(shotDifficultyDiffHist_GivenMissedLastShot)) + 30\n\nplt.figure();\nplt.subplot(2,1,1); plt.bar(difficultyDiffBins[:-1], shotDifficultyDiffHist_GivenMadeLastShot, width=barWidth); plt.xlim((-1,1)); plt.ylim((0,maxHeight))\nplt.title('made last shot'); plt.ylabel('counts')\nplt.subplot(2,1,2); plt.bar(difficultyDiffBins[:-1], shotDifficultyDiffHist_GivenMissedLastShot, width=barWidth); plt.xlim((-1,1)); plt.ylim((0,maxHeight))\nplt.title('missed last shot'); plt.xlabel('chance to make curr shot - chance to make prev shot'); plt.ylabel('counts')\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### We can see that the plot is heavier on the left side\n### It is therefore even more evident now that kobe feels he's \"In The Zone\" after making a shot \nand therefore he allows himself to attempt more difficult shots"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Some of you might be wondering about wheather it's simply regression to the mean or not\nthis thinking is sound, since all made attempts are inherently biased towards easier shots, and if we use relative meassures such as \"shot difficulty change\" we will for sure get this effect by simply \"going back to the mean\", so we need to make sure this isn't it."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% is this regression to the mean?\n\nplt.rcParams['figure.figsize'] = (8, 8)\n\naccuracyAllShots    = data['shot_made_flag'].mean()\naccuracyAfterMade   = afterMadeData['shot_made_flag'].mean()\naccuracyAfterMissed = afterMissedData['shot_made_flag'].mean()\n\nstandardErrorAllShots = np.sqrt(accuracyAllShots*(1-accuracyAllShots)/data.shape[0])\nstandardErrorAfterMade = np.sqrt(accuracyAfterMade*(1-accuracyAfterMade)/afterMadeData.shape[0])\nstandardErrorAfterMissed = np.sqrt(accuracyAfterMissed*(1-accuracyAfterMissed)/afterMissedData.shape[0])\n\naccuracyVec = np.array([accuracyAfterMade,accuracyAllShots,accuracyAfterMissed])\nerrorVec = np.array([standardErrorAfterMade,standardErrorAllShots,standardErrorAfterMissed])\n\nbarWidth = 0.7\nxLocs = np.arange(len(accuracyVec))\n\nfig, h = plt.subplots(); h.bar(xLocs, accuracyVec, barWidth, color='b', yerr=errorVec)\nh.set_xticks(xLocs+0.5*barWidth); h.set_xticklabels(('after made', 'all shots', 'after missed'))\nplt.ylim([0.41,0.47]); plt.xlim([-0.3,3]); plt.title('not regression to the mean')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### OK, now we've established that it's not simply regression to the mean, and that there are infact two different groups of shots with very different accuracies, the question arises:"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Is Kobe right in his \"Hot Hand\" feeling? \nMaybe Kobe really is \"in the zone\" and therefore it's \"OK\" for him to take on more difficult shots?"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% but wait, maybe kobe is making more difficult shots because he's \"in the zone\"\n\npredictedShotPercentAfterMade = np.array(shotChancesListAfterMade).mean()\npredictedStadardDev = np.sqrt(predictedShotPercentAfterMade*(1-predictedShotPercentAfterMade))\nstadardError = predictedStadardDev/np.sqrt(len(shotChancesListAfterMade))\npredPlusErr  = predictedShotPercentAfterMade + 2*stadardError\npredMinusErr = predictedShotPercentAfterMade - 2*stadardError\nactualShotPercentAfterMade = float(totalMadeAfterMade)/totalAttemptsAfterMade\n\nprint(\"-----------------------------------------------------\")\nprint('provided that kobe MADE the previous shot:')\nprint('according to \"shotDifficulty\" model, 95% confidence interval ['+ str(predMinusErr)+', '+str(predPlusErr)+']')\nprint('and Kobe actually made ' + str(actualShotPercentAfterMade) + ', which is within confidence interval')\nprint(\"-----------------------------------------------------\")\n\npredictedShotPercentAfterMissed = np.array(shotChancesListAfterMissed).mean()\npredictedStadardDev = np.sqrt(predictedShotPercentAfterMissed*(1-predictedShotPercentAfterMissed))\nstadardError = predictedStadardDev/np.sqrt(len(shotChancesListAfterMissed))\npredPlusErr  = predictedShotPercentAfterMissed + 2*stadardError\npredMinusErr = predictedShotPercentAfterMissed - 2*stadardError\nactualShotPercentAfterMissed = float(totalMadeAfterMissed)/totalAttemptsAfterMissed\n\nprint(\"-----------------------------------------------------\")\nprint('provided that kobe MISSED the previous shot:')\nprint('according to \"shotDifficulty\" model, 95% confidence interval ['+ str(predMinusErr)+', '+str(predPlusErr)+']')\nprint('and Kobe actually made ' + str(actualShotPercentAfterMissed) + ', which is within confidence interval')\nprint(\"-----------------------------------------------------\")\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### We can see that the accuracy is completely explained by the \"shotDifficulty\" model we've created, that doesn't contain any hot hand related features.\n# The answer looks to be that Kobe doesn't have a \"Hot Hand\" effect"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### let's now try to visualize this a little better"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% let's try and visualize this - show scatter plot of after made and after missed shots\nplt.rcParams['figure.figsize'] = (16, 8)\n\nafterMissedData = data.ix[afterMissedShotsList,:]\nafterMadeData = data.ix[afterMadeShotsList,:]\n\nplt.figure();\nplt.subplot(1,2,1); plt.title('shots after made')\nplt.scatter(x=afterMadeData['loc_x'],y=afterMadeData['loc_y'],c=afterMadeData['shotLocationCluster'],s=50,cmap='hsv',alpha=0.06)\ndraw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270);\n\nplt.subplot(1,2,2); plt.title('shots after missed');\nplt.scatter(x=afterMissedData['loc_x'],y=afterMissedData['loc_y'],c=afterMissedData['shotLocationCluster'],s=50,cmap='hsv',alpha=0.06)\ndraw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270);"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Keen eyes can see differences in density here, but it's not very clear, so let's show the data in the gaussians format, hoping that it will be clearer"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#%% show shot attempts of after made and after missed shots\n\nplt.rcParams['figure.figsize'] = (11, 8)\n\nvariableCategories = afterMadeData['shotLocationCluster'].value_counts().index.tolist()\nclusterFrequency = {}\nfor category in variableCategories:\n    shotsAttempted = np.array(afterMadeData['shotLocationCluster'] == category).sum()\n    clusterFrequency[category] = float(shotsAttempted)/afterMadeData.shape[0]\n\nellipseTextMessages = [str(100*clusterFrequency[x])[:4]+'%' for x in range(numGaussians)]\nDraw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages)\ndraw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270); plt.title('after made shots')\n\nvariableCategories = afterMissedData['shotLocationCluster'].value_counts().index.tolist()\nclusterFrequency = {}\nfor category in variableCategories:\n    shotsAttempted = np.array(afterMissedData['shotLocationCluster'] == category).sum()\n    clusterFrequency[category] = float(shotsAttempted)/afterMissedData.shape[0]\n\nellipseTextMessages = [str(100*clusterFrequency[x])[:4]+'%' for x in range(numGaussians)]\nDraw2DGaussians(gaussianMixtureModel, ellipseColors, ellipseTextMessages)\ndraw_court(outer_lines=True); plt.ylim(-60,440); plt.xlim(270,-270); plt.title('after missed shots')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "### Now it's very evident that after missing a shot, kobe is much more likely to throw directly from under the basket relative to after making a shot (27% vs 19%) \n### It's also very evident that after making a shot, kobe is much more likely to try a 3 pointer as his next shot"
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}