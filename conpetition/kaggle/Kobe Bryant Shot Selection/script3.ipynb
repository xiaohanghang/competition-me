{"cells":[
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Let's perform analysis!\n\nHello, I'm Dixhom. Here I talk about how to preform feature engineering, delete unwanted variables, build a model and make submission data! So this is a tutorial for data science beginners. So let's get the ball rolling.\n\n(This is for a kaggle competition 'Kobe Bryant Shot Selection' (https://www.kaggle.com/c/kobe-bryant-shot-selection))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import KFold"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# import data\nfilename= \"../input/data.csv\"\nraw = pd.read_csv(filename)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Feature engineering\nNow let's start feature engineering. There are many features which should be modified or deleted for brevity. Let's take a look into variables.\n\nFirst, let's take a look at all the variables."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "raw.head()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## Dropping nans\nWe are gonna make a variable without `nan` for our exploratory analysis. "
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "nona =  raw[pd.notnull(raw['shot_made_flag'])]"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## loc_x, loc_y, lat and lon\nWhat do these mean? From their names, these sound like **location_x, location_y, latitude and longitude**. Let's confirm this assumption. "
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "alpha = 0.02\nplt.figure(figsize=(10,10))\n\n# loc_x and loc_y\nplt.subplot(121)\nplt.scatter(nona.loc_x, nona.loc_y, color='blue', alpha=alpha)\nplt.title('loc_x and loc_y')\n\n# lat and lon\nplt.subplot(122)\nplt.scatter(nona.lon, nona.lat, color='green', alpha=alpha)\nplt.title('lat and lon')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "These plot are shaped like basket ball courts. So loc_x, loc_y, lat and lon seem to mean the position from which the ball was tossed. However, since the region under the net is half-circle-shaped, it would be more suitable to transform the variable into **polar coodinate**."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "raw['dist'] = np.sqrt(raw['loc_x']**2 + raw['loc_y']**2)\n\nloc_x_zero = raw['loc_x'] == 0\nraw['angle'] = np.array([0]*len(raw))\nraw['angle'][~loc_x_zero] = np.arctan(raw['loc_y'][~loc_x_zero] / raw['loc_x'][~loc_x_zero])\nraw['angle'][loc_x_zero] = np.pi / 2 "
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Since some of loc_x values cause an error by zero-division, we set just `np.pi / 2` to the corresponding rows.\n\n## minutes_remaining and seconds_remaining\n`minutes_remaining` and `seconds_remaining` seem to be a pair, so let's combine them together."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "raw['remaining_time'] = raw['minutes_remaining'] * 60 + raw['seconds_remaining']"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## action_type, combined_shot_type, shot_type\nThese represents how the player shot a ball."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print(nona.action_type.unique())\nprint(nona.combined_shot_type.unique())\nprint(nona.shot_type.unique())"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## Season\n`Season` looks like consisting of two parts."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "nona['season'].unique()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "`Season` seems to be composed of two parts: season year and season ID. Here we only need season ID. Let's modify the data."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "raw['season'] = raw['season'].apply(lambda x: int(x.split('-')[1]) )\nraw['season'].unique()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## team_id and team_name\nThese contain the same one value for each. Seem useless. "
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print(nona['team_id'].unique())\nprint(nona['team_name'].unique())"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## opponent , matchup\nThese are basically the same information. "
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "pd.DataFrame({'matchup':nona.matchup, 'opponent':nona.opponent})"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Only opponent is needed."
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## Shot distance\nWe already defined this."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "plt.figure(figsize=(5,5))\n\nplt.scatter(raw.dist, raw.shot_distance, color='blue')\nplt.title('dist and shot_distance')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "`shot_distance` is proportional to `dist` and this won't be necessary.\n\n## shot_zone_area, shot_zone_basic, shot_zone_range\nThese sound like some regions on the court, so let's visualize it."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import matplotlib.cm as cm\nplt.figure(figsize=(20,10))\n\ndef scatter_plot_by_category(feat):\n    alpha = 0.1\n    gs = nona.groupby(feat)\n    cs = cm.rainbow(np.linspace(0, 1, len(gs)))\n    for g, c in zip(gs, cs):\n        plt.scatter(g[1].loc_x, g[1].loc_y, color=c, alpha=alpha)\n\n# shot_zone_area\nplt.subplot(131)\nscatter_plot_by_category('shot_zone_area')\nplt.title('shot_zone_area')\n\n# shot_zone_basic\nplt.subplot(132)\nscatter_plot_by_category('shot_zone_basic')\nplt.title('shot_zone_basic')\n\n# shot_zone_range\nplt.subplot(133)\nscatter_plot_by_category('shot_zone_range')\nplt.title('shot_zone_range')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "As we thought, these represent regions on the court. However, these regions can be separated by `dist` and `angle`. So we don't need these."
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## dropping unneeded variables\nLet's drop unnecessary variables."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "drops = ['shot_id', 'team_id', 'team_name', 'shot_zone_area', 'shot_zone_range', 'shot_zone_basic', \\\n         'matchup', 'lon', 'lat', 'seconds_remaining', 'minutes_remaining', \\\n         'shot_distance', 'loc_x', 'loc_y', 'game_event_id', 'game_id', 'game_date']\nfor drop in drops:\n    raw = raw.drop(drop, 1)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## make dummy variables\nWe are going to use randomForest classifier for building our models but this doesn't accept string variables like 'action_type'. So we are going to make dummy variables for those."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# turn categorical variables into dummy variables\ncategorical_vars = ['action_type', 'combined_shot_type', 'shot_type', 'opponent', 'period', 'season']\nfor var in categorical_vars:\n    raw = pd.concat([raw, pd.get_dummies(raw[var], prefix=var)], 1)\n    raw = raw.drop(var, 1)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## separating data for training and submission\nNow let's separate data."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df = raw[pd.notnull(raw['shot_made_flag'])]\nsubmission = raw[pd.isnull(raw['shot_made_flag'])]\nsubmission = submission.drop('shot_made_flag', 1)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "We are separating `df` further into explanatory and response variables."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# separate df into explanatory and response variables\ntrain = df.drop('shot_made_flag', 1)\ntrain_y = df['shot_made_flag']"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "## logloss\nSubmissions are evaluated on the log loss. We are going to use it for evaluating our model."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import scipy as sp\ndef logloss(act, pred):\n    epsilon = 1e-15\n    pred = sp.maximum(epsilon, pred)\n    pred = sp.minimum(1-epsilon, pred)\n    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n    ll = ll * -1.0/len(act)\n    return ll"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Building a model\nNow it's time to build a model. We use randomForest classifier and k-fold cross validation for testing our model.\nWe are going to...\n\n1. pick a `n` from `n_range` for the number of estimators in randomForestClassifier.\n1. divide the training data into 10 pieces\n2. pick 9 of them for building a model and use the remaining 1 for testing a model\n3. repeat the same process for the other 9 pieces.\n4. calculate score for each and take an average of them\n5. pick the next `n` and do the process again\n6. find the `n` which gave the best score among `n_range`\n7. repeat the same process with the tree depth parameter.\n\nYou can change the value of `np.logspace` for searching optimum value in broader area."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import confusion_matrix\nimport time\n\n\n# find the best n_estimators for RandomForestClassifier\nprint('Finding best n_estimators for RandomForestClassifier...')\nmin_score = 100000\nbest_n = 0\nscores_n = []\nrange_n = np.logspace(0,2,num=3).astype(int)\nfor n in range_n:\n    print(\"the number of trees : {0}\".format(n))\n    t1 = time.time()\n    \n    rfc_score = 0.\n    rfc = RandomForestClassifier(n_estimators=n)\n    for train_k, test_k in KFold(len(train), n_folds=10, shuffle=True):\n        rfc.fit(train.iloc[train_k], train_y.iloc[train_k])\n        #rfc_score += rfc.score(train.iloc[test_k], train_y.iloc[test_k])/10\n        pred = rfc.predict(train.iloc[test_k])\n        rfc_score += logloss(train_y.iloc[test_k], pred) / 10\n    scores_n.append(rfc_score)\n    if rfc_score < min_score:\n        min_score = rfc_score\n        best_n = n\n        \n    t2 = time.time()\n    print('Done processing {0} trees ({1:.3f}sec)'.format(n, t2-t1))\nprint(best_n, min_score)\n\n\n# find best max_depth for RandomForestClassifier\nprint('Finding best max_depth for RandomForestClassifier...')\nmin_score = 100000\nbest_m = 0\nscores_m = []\nrange_m = np.logspace(0,2,num=3).astype(int)\nfor m in range_m:\n    print(\"the max depth : {0}\".format(m))\n    t1 = time.time()\n    \n    rfc_score = 0.\n    rfc = RandomForestClassifier(max_depth=m, n_estimators=best_n)\n    for train_k, test_k in KFold(len(train), n_folds=10, shuffle=True):\n        rfc.fit(train.iloc[train_k], train_y.iloc[train_k])\n        #rfc_score += rfc.score(train.iloc[test_k], train_y.iloc[test_k])/10\n        pred = rfc.predict(train.iloc[test_k])\n        rfc_score += logloss(train_y.iloc[test_k], pred) / 10\n    scores_m.append(rfc_score)\n    if rfc_score < min_score:\n        min_score = rfc_score\n        best_m = m\n    \n    t2 = time.time()\n    print('Done processing {0} trees ({1:.3f}sec)'.format(m, t2-t1))\nprint(best_m, min_score)\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Visualizing parameters for randomForest\nBy visualizing the parameters, we can check if the chosen parameter is really the best."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "plt.figure(figsize=(10,5))\nplt.subplot(121)\nplt.plot(range_n, scores_n)\nplt.ylabel('score')\nplt.xlabel('number of trees')\n\nplt.subplot(122)\nplt.plot(range_m, scores_m)\nplt.ylabel('score')\nplt.xlabel('max depth')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Building a final model\nLet's use the parameters we just got for the final model and prediction."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "model = RandomForestClassifier(n_estimators=best_n, max_depth=best_m)\nmodel.fit(train, train_y)\npred = model.predict_proba(submission)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Making submission data\nPredicted shot_made_flag is written to a csv file."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sub = pd.read_csv(\"../input/sample_submission.csv\")\nsub['shot_made_flag'] = pred\nsub.to_csv(\"real_submission.csv\", index=False)"
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}